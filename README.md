# ğŸ¥ Text2SQL Healthcare Analytics System

Transform natural language into precise SQL queries for healthcare data using AI.

---

## ğŸ“˜ Project Overview

The **Text2SQL Healthcare Analytics System** is an AI-powered platform designed to translate natural language questions into optimized SQL queries for analyzing healthcare data stored in ClickHouse databases. This tool empowers commercial teams, data analysts, and healthcare professionals to query complex datasets in plain English without requiring SQL expertise.

---

## ğŸ› ï¸ Methods Used

### 1. HyDE (Hypothetical Document Embeddings)

The system employs HyDE to enhance the accuracy of SQL generation. For each natural language query, the AI generates three hypothetical SQL examples that represent ideal responses. These examples are used to guide the final query generation, reducing hallucinations and improving alignment with the user's intent.

### 2. Tiered Confidence Scoring

A three-tier evaluation system assesses the quality of generated SQL queries:

| Tier | Category                              | Weight |
| ---- | ------------------------------------- | ------ |
| 1    | SQL Syntax & ClickHouse Compatibility | 40%    |
| 2    | Entity Accuracy & Query Intent        | 35%    |
| 3    | Executability & Runtime Performance   | 25%    |

### 3. Healthcare Entity Recognition

Advanced entity detection identifies critical healthcare elements (e.g., drugs, procedures) using domain-specific mappings, enhancing query precision.

### 4. Vector Context Retrieval

The system integrates Weaviate, a vector database, to retrieve semantically relevant context, improving the interpretation of natural language inputs.

---

## ğŸŒŸ Key Features

* ğŸ§  **Natural Language to SQL**: Convert English queries into accurate SQL using advanced AI models.
* ğŸ¥ **Healthcare-Specific Entity Recognition**: Identify and extract drugs, procedures, specialties, locations, and conditions.
* ğŸ¤– **Multi-Model AI Integration**: Supports Google Gemini and local Ollama models (with Ollama as fallback for private execution).
* ğŸ“Š **HyDE SQL Examples**: Enhance output accuracy with hypothetical document embeddings.
* âœ… **Real-time Schema Validation**: Ensure generated SQL aligns with ClickHouse table schemas.
* ğŸ“ˆ **Tiered Confidence Scoring**: Evaluate query accuracy across three tiers.
* ğŸ” **Vector Context Retrieval**: Leverage Weaviate for semantic context enhancement.

---

## ğŸ—ï¸ Architecture

```
text2sql-healthcare/
â”œâ”€â”€ main.py                          # Streamlit frontend
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ system_initializer.py        # System initialization
â”‚   â”œâ”€â”€ query_processor.py           # Text2SQL pipeline
â”‚   â”œâ”€â”€ hyde_generator.py            # HyDE example generation
â”‚   â”œâ”€â”€ context_retriever.py         # Weaviate-based context search
â”‚   â””â”€â”€ confidence_calculator.py     # Tiered confidence scoring
â”œâ”€â”€ models/
â”‚   â””â”€â”€ hybrid_sql_generator.py      # Multi-model generation logic
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ ui_components.py             # UI elements
â”‚   â”œâ”€â”€ logging_utils.py             # Logging utilities
â”‚   â”œâ”€â”€ entity_mapper.py             # Domain-aware entity detection
â”‚   â”œâ”€â”€ query_classifier.py          # Query intent classification
â”‚   â”œâ”€â”€ schema_validator.py          # SQL schema verification
â”‚   â””â”€â”€ sql_evaluator.py             # SQL quality evaluation
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ app_config.py                # Application configuration
â”‚   â”œâ”€â”€ schema.py                    # Database schema definitions
â”‚   â”œâ”€â”€ domain_knowledge.py          # Healthcare domain knowledge
â”‚   â””â”€â”€ prompts.py                   # Prompt templates
â””â”€â”€ requirements.txt                 # Project dependencies
```

---

## ğŸš€ Setup & Installation

### Prerequisites

* Python 3.8+
* ClickHouse Database
* Weaviate Vector Database
* API key for Google Gemini or Ollama model

### Steps

**Clone the repository:**

```bash
git clone <repository-url>
cd text2sql-healthcare
```

**Install dependencies:**

```bash
pip install -r requirements.txt
```

**Create a .env file with the following configuration:**

```env
# Model Keys
GOOGLE_API_KEY=your_google_key
OLLAMA_MODEL=llama3:8b

# ClickHouse
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=8123
CLICKHOUSE_DATABASE=docnexus
CLICKHOUSE_PASSWORD=your_password

# Weaviate
WEAVIATE_URL=http://localhost:8080
WEAVIATE_API_KEY=your_weaviate_key
```

**Run the application:**

```bash
streamlit run main.py
```

---

## ğŸ“Š Methodology

### HyDE (Hypothetical Document Embeddings)

* AI generates 3 SQL examples per query to reduce hallucinations and improve accuracy.

### Tiered Confidence Scoring

* 3-tier system as described above to ensure robust validation.

### Healthcare Entity Recognition

Supports detection of:

* ğŸ§ª **Drugs**: e.g., Ozempic, Trulicity
* âš•ï¸ **Procedures**: e.g., CPT codes
* ğŸ§º **Providers**: e.g., NPIs, specialties
* ğŸ“ **Locations**: e.g., CA, TX
* ğŸ¦  **Conditions**: e.g., ICD codes

### Multi-Model AI Integration

| Model  | Use Case                         |
| ------ | -------------------------------- |
| Gemini | Complex healthcare reasoning     |
| Ollama | Private, offline model execution |

---

## ğŸ—„ï¸ Database Schema

| Table                                              | Description      |
| -------------------------------------------------- | ---------------- |
| `as_lsf_v1`                                        | HCP Payments     |
| `fct_pharmacy_clear_claim_allstatus_cluster_brand` | Claims           |
| `as_providers_v1`                                  | Provider Details |
| `as_providers_referrals_v2`                        | Referrals        |
| `kol_providers_v1`                                 | Opinion Leaders  |
| `kol_scores_v1`                                    | KOL Scores       |

---

## ğŸ“ˆ Example Queries

```sql
"Top prescribers of Ozempic in California"
"Compare prescribing trends between cardiologists and endocrinologists"
"Find cardiologists in Texas with high pharma payments and referral volumes"
```

---

## ğŸ”§ Configuration

Modify settings in `config/app_config.py`:

* Model priority: gemini > ollama
* Prompt tuning
* Timeout settings

---

## ğŸ“ Assumptions

* Consistent use of NPI IDs across datasets.
* ClickHouse schema adheres to the defined format.
* Weaviate vector DB is populated with relevant data.
* Models are stateless and respect data privacy.

---

## âš ï¸ Limitations

* **Weaviate Capacity**: Free version limited to 1,000 records.
* **Open-Source Models**: No fine-tuning capabilities, affecting precision.
* **Single-DB Support**: Only ClickHouse currently supported.
* **Temporal Analysis**: Basic date-based filtering.
* **Streaming Not Supported**: No real-time ingestion or live query processing.
* **Data Visualization**: Tabular only; no charts/graphs yet.

---

## ğŸ”® Future Enhancements

### ğŸ” Architectural Improvements

* âœ… **Model-Agnostic Pipeline**: Dynamic LLM switching based on query type and load.
* ğŸ› ï¸ **MCP Tools & Pipelines**: Incorporate MLOps for monitoring, retraining, and versioning.
* ğŸ§  **Agentic Framework Integration**: Enable autonomous query decomposition with LangGraph or AutoGen.
* ğŸ§¹ **Context Engineering Feedback Loop**: Implement human-in-the-loop corrections.
* ğŸŒ **Multi-DB Support**: Add PostgreSQL, MySQL, and Snowflake.

---

## ğŸ”’ Security & Compliance

* Ensure **HIPAA compliance**
* No **PHI** exposure
* Secure API key storage
* Optional **rate limiting** and **audit logging**

---

## ğŸš» Troubleshooting

| Issue           | Resolution                              |
| --------------- | --------------------------------------- |
| Model Timeout   | Verify .env keys and network            |
| Weaviate Errors | Ensure schema and index exist           |
| Low Confidence  | Tune prompts and entity mappings        |
| SQL Errors      | Check for schema mismatch in ClickHouse |

---

## ğŸ“š Dependencies

```
streamlit
clickhouse-connect
weaviate-client
google-generativeai
ollama
sqlglot
pandas
numpy
python-dotenv
```

---

## ğŸ¤ Contributing

1. Fork the repository.
2. Create your branch: `git checkout -b feature-branch`.
3. Add features with tests.
4. Commit: `git commit -m "Add new feature"`.
5. Push: `git push origin feature-branch`.
6. Open a pull request.

---
